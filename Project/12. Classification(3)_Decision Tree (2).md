# 2022-1 학기 데이터마이닝 프로젝트_(12)  

🐍 저번 글에서는 결정 트리를 통해 Classification을 진행했다. correlation 분석으로 얻어진 4개의 attribute set과 PCA dataframe에 대해서 결정트리 모델을 사용해 예측력을 평가해 보았다. 이번 글에서는 이렇게 얻어진 결정 트리 모델을 시각화해볼 것이다.  

***  

## 1. 라이브러리  

📌 decision tree를 위한 graphviz 라이브러리를 사용한다. 이 라이브러리는 처음 설치할 때 바이너리 코드의 경로를 잘 설정해줘야한다.  

📌  데이터의 크기가 크지 않은 경우에는 만들어진 결정 트리를 살펴보기 어렵지 않지만, 이번에 우리가 사용한 데이터는 column이 많기에 한번에 파악하기 어렵다. 따라서 이렇게 만들어진 결정 트리를 .png 파일로 저장할 필요가 있다. 이때 사용하는 라이브러리가 pydotplus 이다.  


```py  
# decision tree를 위한 export_graphviz 라이브러리 임포트
# sklearn 모듈의 tree 라이브러리 임포트
from sklearn.tree import export_graphviz
import graphviz
from sklearn import tree
from os import system

# 결정트리를 png 형태로 저장하기 위한 라이브러리 임포트
import pydotplus
```  

***  

## 2. Attribute set 4 [age, aphi, aplo, cholesterol, gluc, BMI] Decision Tree  

📌 test set에 대해 높은 accuracy를 보인 attribute set 4에 대해서 시각화를 진행할 것이다.  

```py
# attribute set 4에 대한 결정트리 시각화 (max_depth = 5)
dot_data = tree.export_graphviz(accuracy_test(cardio_4_feat, 5)[0],        # 의사결정나무 모형 대입
                               out_file = None,                            # file로 변환할 것인가
                               feature_names = cardio_4_feat.columns,      # feature 이름
                               class_names = cardio.target_rand,           # target 이름
                               filled = True,                              # 그림에 색상을 넣을것인가
                               rounded = True,                             # 반올림을 진행할 것인가
                               special_characters = True)                  # 특수문자를 사용하나

graph = pydotplus.graph_from_dot_data(dot_data)
graph.set_size('"60,30!"')
graph.write_png('atribute_4_tree.png')
```  

<p align="center"><img src="https://user-images.githubusercontent.com/65170165/199865789-68d81a6a-ef75-461d-a200-845feaaacb6e.png" width="1000" /></p>  

📌 앞서 말한 대로 정말 자잘자잘한 형태로 나온다. 구글링을 해보면 대부분의 결정트리에서 iris 데이터를 사용한다. iris 데이터는 정말 유명한 데이터이고 그만큼 정리도 잘 되어 있는 데이터이기에 깨끗한 결정 트리를 관찰할 수 있지만, 우리가 사용한 데이터는 완전한 균일화가 되기에는 어렵다. 위의 결정 트리의 결과를 설명하면 다음과 같다.  

- 결정 트리의 목적은 데이터가 균일할 수 있도록 계속해서 데이터를 분류해 나가는 것이다.  
- 데이터를 분류하는 기준은 균일하게 분류된 그룹을 기준으로 만들어진 규칙이다.  
- 첫 그룹을 잘 나눌 수 있는 기준을 통해 다음 두 개의 자식 노드로 만들고, 그 다음 기준을 통해 다시 자식 노드를 만든다.<br>  
  
- 각 그룹의 균일도를 측정하는 방법에는 크게 두 가지가 있다.<br>  
  
  - Entropy : 데이터의 complexity. 다른 값이 많이 섞여 있는 경우 높고, 같은 값이 많은 경우 낮다.  
    - 이 Entropy가 낮은 그룹을 기준으로 자식 노드로 나눈다.  
  - gini : 0~1의 값으로 데이터의 불평등함을 나타낸다. 데이터가 같은 값을 많이 가질수록 불평등하다는 의미이다.  
    - gini 계수가 높을수록 데이터가 균일하다는 의미이다.  
      
- 우리는 결정트리를 만들 때 엔트로피를 사용하였기 때문에, 위의 결정트리를 보면 엔트로피로 기준이 잡혀있는 것을 확인 할 수 있다. 결정트리의 목적은 모든 그룹을 균일하도록 만들어 그 예측력을 높이는 데에 있기 때문에, 트리의 깊이를 조정하며 엔트로피값을 최적화한다. 우리가 사용한 결정 트리는 깊이가 5이기 때문에 5개까지만 만들어졌다.  
  
       
<p align="center"><img src="https://user-images.githubusercontent.com/65170165/199880779-30e0cbea-67e6-4062-acd0-bdf399cecaac.jpg" width="600" /></p>  

- 결정 트리를 살짝 확대해서 가져왔다. 기준을 if 문으로 나눠서 자식 노드가 갈라지며, 그에 따른 엔트로피 값을 계산하는 것을 확인 할 수 있다. 따라서 어떤 노드는 엔트로피가 0인 반면, 아닌 노드도 있다는 것을 확인 할 수 있다.  
  
***  

## 3. PCA Decision Tree  

📌 이번에는 PCA 결과 만들어진 데이터를 가지고 결정 트리를 시각화 할 것이다.  

```py
# PCA Dataframe에 대한 결정트리 시각화 (max_depth = 6)
dot_data_PCA = tree.export_graphviz(clf_PCA,        # 의사결정나무 모형 대입
                               out_file = None,     # file로 변환할 것인가
                               feature_names = PCA_df.feat.columns, # feature 이름
                               class_names = PCA_df.target,   # target 이름
                               filled = True,        # 그림에 색상을 넣을것인가
                               rounded = True,       # 반올림을 진행할 것인가
                               special_characters = True)    # 특수문자를 사용하나

graph_PCA = pydotplus.graph_from_dot_data(dot_data_PCA)
graph_PCA.set_size('"60,30!"')
graph_PCA.write_png('PCA_tree.png')
```  
<p align="center"><img src="https://user-images.githubusercontent.com/65170165/199866052-9c77776c-0ab9-4056-9a08-d0cd7877d13f.png" width="1000" /></p>  

***  

🐍 이번 글을 통해 결정 트리를 시각화하였다. graphviz를 설치하는 과정이 까다로웠지만 눈에 띄는 결과가 나오니 재밌었다.  

🐍 결정 트리만 가지고서 모델을 학습시키고 예측하는 것은 쉽지 않을 것 같다. 다음 글에서는 이 트리들이 모여있는 랜덤 포레스트를 사용해볼 것이다.  

***
